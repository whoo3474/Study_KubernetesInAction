# 15장 파드와 클러스터 노드의 오토스케일링

파드로 실행되는 애플리케이션은 레플리카셋, 디플로이먼트 등의 replicas 필드 값을 수정하여 수동으로 확장 및 축소가 가능하다. 그러나 스케일을 수동으로 제어하는 건 순간적인 부하를 예측할 수 있거나, 부하가 장시간에 걸쳐 점진적으로 변화하는 경우에 적절한 방법이다. 예측할 수 없는 갑작스러운 트래픽 증가 현상을 수동으로 개입해 처리하는 것은 이상적이지 않다.

## 15.1 수평적 파드 오토스케일링

수평적 파드 오토스케일링은 레플리카 수가 자동으로 조정되는 것을 말한다. 이것은 Horizontal 컨트롤러에 의해 수행된다. 컨트롤러는 주기적으로 파드 메트릭을 확인하고 HorizontalPodAutocaler 리소스에 설정돼 있는 값을 만족하는 레플리카 수를 계산하고 대상 리소스의 replicas 필드 값을 조절한다.

### 15.1.1 오토스케일링 프로세스 이해

오토스케일링 프로세스는 메트릭 수집, 필요 파드 수 계산, replicas 필드 갱신 이렇게 세 단계로 나눌 수 있다.

**파드 메트릭 얻기**

파드의 메트릭은 kubelet에서 실행되는 cAdvisor 에이전트에 의해 수집된다. 수집된 메트릭은 클러스터 전역 구성 요소인 힙스터(1.11 부터 metrics-server 사용)에 의해 집계된다. 오토스케일러 컨트롤러는 REST API를 통해 파드의 메트릭을 가져온다.

**필요한 파드 수 계산**

모든 레플리카에서 메트릭을 수집하고 지정된 목표 값과 가능한 가깝게 될 수 있는 출력 값을 계산한다. 출력 값은 정수(파드 레플리카 수)이다. 단순하게 보면 평균치를 계산하지만, 메트릭 값이 불안정한 상태에서 빠르게 변할 때 오토스케일러가 같이 요동치지 않도록 하기 위해 실제 계산은 좀 더 복잡하다.

**스케일링된 리소스의 레플리카 수 갱신**

오토스케일러 컨트롤러는 스케일 대상 리소스의 replicas 필드를 스케일 서브 리소스를 통해 변경한다. 이는 오토스케일러가 리소스의 세부 사항을 알 필요가 없도록 해준다.

### 15.1.2 CPU 사용률 기반 스케일링

서비스의 CPU 사용량이 100%에 도달하면 더 이상 요구에 대응할 수 없어 스케일 업(수직, 파드가 사용하는 CPU 양 증가)이나 스케일 아웃(수평, 파드 수 증가)이 필요하다. CPU 사용량은 대개 불안정하기 때문에 파드 전체 평균 CPU 부하가 80%에 도달하거나 초과할 때 스케일 아웃을 수행하는 것이 좋다. 그럼 이 사용량 80%라는 것은 어떤 기준으로 결정되는 걸까?

오토스케일러에 한해서는 파드의 CPU 사용률을 결정할 때 파드의 실제 CPU 사용량과 CPU 요청량(request)을 비교한다. 이는 오토스케일링이 필요한 파드는 직접적(리소스 명세에 명시)이든 간접적(LimitRange 등 사용)으로든 CPU 요청이 설정되어 있어야 한다는 것을 의미한다.

**CPU 사용량을 기반으로 HorizontalPodAutoscaler 생성**

실습 진행을 위해 먼저 metrics server 설치해야 한다.

yaml 다운로드

```
wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

`component.yaml` 에서 Deployment에 아래와 같이 `--kubelet-insecure-tls` 옵션 추가

```
args:
  - --cert-dir=/tmp
  - --secure-port=4443
  - --kubelet-insecure-tls
```

배포가 완료되면 `kubectl top` 명령어를 사용할 수 있다.

```
kubectl top nodes
kubectl top pods
```


실습을 진행하기 위해 아래의 템플릿을 이용해 디플로이먼트롤 생성한다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: lukas/kubia:v1
        name: nodejs
        resources:
          requests:
            cpu: 100m
```

```
kubectl apply -f deployment.yaml
```

`kubectl autoscale` 명령어를 통해 hpa를 생성하였다.

```
kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5
```

```
kubectl get autoscale kubia -o yaml
```

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: kubia
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  targetCPUUtilizationPercentage: 30
status:
  currentReplicas: 0
  desiredReplicas: 0
```

`kubectl get` 명령어를 통해 hpa를 확인할 수 있다. TARGETS 에는 현재 사용량와 스케일링을 위한 기준값이 나타난다.

```
kubectl get hpa
```

```
NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   0%/30%    1         5         1          27m
```

 metric server가 정상적으로 작동하지 않으면 현재 사용량이 `<unknown>` 으로 표시된다.

```
NAME    REFERENCE          TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   <unknown>/30%   1         5         1          9m49s
```

**스케일 업 일으키기**

CPU 사용량을 증가시키기 위해 서비스 리소스를 생성하고 부하생성기를 생성한다.

```
kubectl expose deployment kubia --port=80 --target-port=8080
```

```
kubectl run -it --rm --restart=Never loadgenerator --image=busybox -- sh -c "while true; do wget -O - -q http://kubia.default; done"
```

```
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
This is v1 running in pod kubia-5bb46d6998-bzgpf
...
```

**오토스케일러가 디플로이먼트를 스케일 업하는 것 확인**

CPU 사용량이 83%까지 상승한 것을 확인할 수 있다.

```
kubectl get hpa
```

```
NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   83%/30%   1         5         1          2m
```

`kubectl describe` 명령어를 통해 이벤트를 확인해보면 스케일링이 발생한 것을 확인할 수 있다.

```
kubectl desribe hpa kubia
```

```
Events:
  Type     Reason                        Age                 From                       Message
  ----     ------                        ----                ----                       -------
  Warning  FailedComputeMetricsReplicas  22m (x13 over 34m)  horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  Warning  FailedGetResourceMetric       19m (x16 over 34m)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  Warning  FailedGetResourceMetric       14m (x2 over 15m)   horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)
  Normal   SuccessfulRescale             3m13s               horizontal-pod-autoscaler  New size: 2; reason: cpu resource utilization (percentage of request) above target
  Normal   SuccessfulRescale             2m13s               horizontal-pod-autoscaler  New size: 3; reason: cpu resource utilization (percentage of request) above target
```

디플로이먼트에도 스케일링 관련 이벤트가 기록되어 있다.

```
kubectl describe deploy kubia
```

```
Events:
  Type    Reason             Age                  From                   Message
  ----    ------             ----                 ----                   -------
  Normal  ScalingReplicaSet  39m                  deployment-controller  Scaled up replica set kubia-84ff444c4b to 3
  Normal  ScalingReplicaSet  38m                  deployment-controller  Scaled up replica set kubia-5bb46d6998 to 1
  Normal  ScalingReplicaSet  37m                  deployment-controller  Scaled down replica set kubia-84ff444c4b to 2
  Normal  ScalingReplicaSet  37m                  deployment-controller  Scaled down replica set kubia-84ff444c4b to 1
  Normal  ScalingReplicaSet  37m                  deployment-controller  Scaled down replica set kubia-84ff444c4b to 0
  Normal  ScalingReplicaSet  11m                  deployment-controller  Scaled down replica set kubia-5bb46d6998 to 1
  Normal  ScalingReplicaSet  3m34s (x2 over 37m)  deployment-controller  Scaled up replica set kubia-5bb46d6998 to 2
  Normal  ScalingReplicaSet  2m34s (x2 over 37m)  deployment-controller  Scaled up replica set kubia-5bb46d6998 to 3
```

레플리카가 3으로 증가했고 평균 CPU 사용량이 25%로 감소하였다.

```
kubectl get hpa
```

```
NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   22%/30%   1         5         3          4m
```

**최대 스케일링 비율 이해**

스케일링을 시도할 때 한 번에 추가할 수 있는 레플리카의 수는 제한되어 있다.

| 기존 레플리카 | 최대 확장 레플리카 |
| --- | --- |
| 1개 | 4개 |
| 2개 | 4개 |
| 3개 이상 | 2배 |

지난 3분 동안 스케일링 이벤트가 발생하지 않은 경우에만 스케일 업이 일어난다. 스케일 다운 이벤트는 5분 간격으로 일어난다.

**기존 HPA 오브젝트에서 목표 메트릭 값 변경**

기존 30에서 100으로 변경해보자.

```yaml
...
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  targetCPUUtilizationPercentage: 100
...
```

```
kubectl describe hpa kubia
```

```
Events:
  Type    Reason             Age    From                       Message
  ----    ------             ----   ----                       -------
  Normal  SuccessfulRescale  13m    horizontal-pod-autoscaler  New size: 3; reason: cpu resource utilization (percentage of request) above target
  Normal  SuccessfulRescale  3m20s  horizontal-pod-autoscaler  New size: 1; reason: All metrics below target
```

```
kubectl get hpa -w
```

```
NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   32%/30%   1         5         3          7m18s
kubia   Deployment/kubia   32%/100%   1         5         3          7m45s
kubia   Deployment/kubia   31%/100%   1         5         3          8m
kubia   Deployment/kubia   25%/100%   1         5         3          9m
kubia   Deployment/kubia   27%/100%   1         5         3          10m
kubia   Deployment/kubia   21%/100%   1         5         3          11m
kubia   Deployment/kubia   17%/100%   1         5         3          12m
kubia   Deployment/kubia   43%/100%   1         5         1          13m
```

리소스를 수정한 후에 변경 사항은 오토스케일러 컨트롤러에 의해 감지돼 동작한다. 위 예시를 보면 스케일 다운이 발생하는 것을 확인할 수 있다.

HAP 리소스를 삭제하고 다른 목표 값으로 다시 생성하는 것도 할 수 있다. 그러나 HPA 리소스를 삭제하는 것은 오토스케일링을 비활성화하는 것이기 때문에 기존 크기가 계속 유지된다. 새로운 HPA를 생성하면 새로 생성된 HPA 스펙에 따라 오토스케일링이 다시 시작된다.

부하발생기를 중단시키는 경우에도 스케일 다운이 발생한다.

```
kubectl get hpa -w
```

```
NAME    REFERENCE          TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   24%/100%   1         5         3          43m
kubia   Deployment/kubia   23%/100%   1         5         3          44m
kubia   Deployment/kubia   6%/100%    1         5         3          45m
kubia   Deployment/kubia   0%/100%    1         5         3          46m
kubia   Deployment/kubia   0%/100%    1         5         2          47m
kubia   Deployment/kubia   0%/100%    1         5         2          48m
kubia   Deployment/kubia   0%/100%    1         5         1          49m
kubia   Deployment/kubia   0%/100%    1         5         1          50m
```

### 15.1.3 메모리 소비량에 기반을 둔 스케일링

메모리 기반 오토스케일링은 CPU 기반 오토스케일링에 비해 문제가 많다. 메모리를 해제하는 작업은 애플리케이션이 직접 해야 하며 시스템이 할 수 있는 것이 아니다. 만약 애플리케이션이 스케일업이 일어남에도 불구하고 각 파드의 메모리 사용량이 이전과 동일하다면 HPA는 리소스에 설정된 최대 파드 수에 도달할 때까지 계속 스케일 업을 진행할 것이다.

### 15.1.4 사용자 정의 메트릭 기반 스케일링

> `autoscaling/v1` 은 사용자 정의 메트릭 기반으로 스케일링을 할 수 없다.

**리소스 메트릭**

리소스 메트릭은 리소스를 기반으로 오토스케일링을 결정한다. 앞에서 설명한 것과 유사하므로 넘어간다.

- v1
    
    ```yaml
    apiVersion: autoscaling/v1
    kind: HorizontalPodAutoscaler
    metadata:
      name: kubia
    spec:
      maxReplicas: 5
      minReplicas: 1
      scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: kubia
      targetCPUUtilizationPercentage: 30
    ```
    

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: kubia-v2beta1-resources
  namespace: default
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 50
```

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: kubia-v2beta2-resources
  namespace: default
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization # Utilization, Value, or AverageValue
        averageUtilization: 50
```

**파드 메트릭**

Pods 유형은 파드와 관련된 다른 메트릭(사용자 정의 메트릭 포함)을 직접 참조하는데 사용된다.

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: kubia-v2beta1-pods
  namespace: default
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  metrics:
  - type: Pods
    pods:
      metricName: qps
      targetAverageValue: 100
```

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: kubia-v2beta2-pods
  namespace: default
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  metrics:
  - type: Pods
    pods:
      metric:
        name: qps
      target:
        type: AverageValue # Utilization, Value, or AverageValue
        averageValue: 50
```

**오브젝트 메트릭**

Object 유형은 파드에 직접 관련되지 않는 메트릭을 기반으로 오토스케일링을 수행하도록 한다.

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: kubia-v2beta1-object
  namespace: default
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  metrics:
  - type: Object
    object:
      metricName: latencyMillis
      target:
        apiVersion: extensions/v1beta1
        kind: Ingress
        name: frontend
      targetValue: 50
```

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: kubia-v2beta2-object
  namespace: default
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  metrics:
  - type: Object
    object:
      describedObject:
        apiVersion: extensions/v1beta1
        kind: Ingress
        name: frontend
      metric:
        name: latencyMillis
      target:
        type: Value # Utilization, Value, or AverageValue
        value: 50
```

### 15.1.5 오토스케일링에 적합한 메트릭 결정

모든 메트릭이 오토스케일링의 기반으로 사용하기에 적합한 것은 아니다. 레플리카 수를 늘리면 오토스케일링의 기준이 되는 메트릭의 평균 값이 선형적으로 감소해야 오토스케일러가 제대로 동작할 수 있다. 따라서 특정 메트릭을 오토스케일러의 기반 항목으로 결정하기 전에, 파드 수가 증가하고 감소할 때 메트릭 값이 어떻게 변화하는지 살펴보아야 한다.

### 15.1.6 레플리카를 0으로 감소

오토스케일러는 파드 수를 0으로 감소시키지 않는다. 만약 파드 수를 0으로 축소할 수 있게 만들면 하드웨어 사용률을 크게 높일 수 있을 것이다. 이러한 기능을 idling, un-idling이라고 한다. 특정 서비스를 제공하는 파드를 0으로 축소할 수 있게 하고, 새로운 요청이 들어오면 파드가 깨어나 요청을 처리할 수 있을 때까지 차단돼 있다가 이후에 요청이 파드로 전달된다. 쿠버네티스에서는 현재 이 기능을 제공하지 않지만, 나중에 추가될 수 있다.

## 15.2 수직적 파드 오토스케일링

수평적 확장이 불가능한 애플리케이션의 경우 수직적으로 확장하는 것이 필요할 수 있다. 즉, 파드의 CPU와 메모리를 더 많이 할당하는 것이다. 현재는 기존에 존재하는 파드의 리소스 요청이나 한계를 변경할 수 없다.

vpa README

[https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler)

vpa 관련 이슈

[https://github.com/kubernetes/autoscaler/issues?q=vpa+label%3Avertical-pod-autoscaler](https://github.com/kubernetes/autoscaler/issues?q=vpa+label%3Avertical-pod-autoscaler)

## 15.3 수평적 클러스터 노드 확장

만약 쿠버네티스 클러스터의 모든 노드가 한계에 도달해 더 이상 파드를 추가할 수 없을 때는 어떻게 해야할까? 이 경우에는 기존 파드 중 몇 개를 삭제하거나 파드가 사용하는 자원을 줄여서 리소스를 확보할 수 있다. 또는 새로운 노드를 추가해 사용할 수 있는 리소스를 증가시킬수 도 있다. 온프레미스 환경에서는 물리적으로 새로운 머신을 추가해야 한다. 그러나 쿠버네티스 클러스터를 클라우드 서비스를 통해 운영한다면, API 호출이나 몇 번의 클릭만으로 쉽게 노드를 추가할 수 있다. 그리고 클러스터 오토스케일러를 통해 추가적인 노드가 필요한 것을 탐지하여 자동으로 노드를 추가하도록 할  수 있다.

### 15.3.1 클러스터 오토스케일러 소개

클러스터 오토스케일러는 리소스 사용량에 따라 노드를 추가하기도 하고 회수하기도 한다.

**클라우드 인프라스트럭처에 추가 노드 요청**

새 파드가 생성된 후 스케줄러가 기존 노드에 스케줄링을 할 수 없는 경우, 클러스터 오토스케일러는 사용 가능한 노드 그룹을 검사해 최소한 하나의 노드 유형이 스케줄링 되지 않은 파드를 수용할 수 있는지 확인한다. 만약 적합한 노드 그룹이 있다면 해당되는 유형의 노드를 추가하도록 요청한다. 만약 적합한 노드 그룹이 둘 이상이라면 가장 좋은 옵션을 선택한다. 좋은 선택의 의미는 설정 가능하다는 것을 의미하며, 최악의 경우 무작위로 선택한다. 새 노드가 시작되면, 해당 노드의 kubelet이 api서버를 통해 노드 리소스를 만들어 노드를 등록한다. 노드 등록이 완료되면 파드를 해당 노드에 스케줄링 할 수 있다.

**노드 종료**

오토스케일러는 노드의 CPU와 메모리 요청을 모니터링해 50% 미만인 경우 해당 노드를 필요하지 않은 것으로 간주한다. 그러나 리소스 요청이 낮더라도 시스템 파드(데몬셋 제외)나 단일 파드가 실행 중이거나 로컬 저장소를 가진 파드가 실행중인 경우 종료 대상에서 제외시킨다. 즉, 해당 노드에서 실행중인 파드가 다른 노드로 다시 스케줄링 될 수 있는 경우에만 노드가 종료되고 반환될 수 있다.

### 15.3.2 클러스터 오토스케일러 활성화

클라우드 제공자마다 활성화 방법이 다르므르 [쿠버네티스 클러스터 오토스케일러 문서](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)와 각 클라우드 제공자에서 제공하는 문서들을 확인한다.

### 15.3.3 클러스터 스케일 다운 동안에 서비스 중단 제한

오토스케일러나 시스템 관리자로 인해(kubectl drain) 노드 종료가 이뤄질 때, 해당 노드에서 실행되는 파드가 제공하는 서비스가 중단되지 않도록 할 수 있다. 쿠버네티스에서는 PodDisruptionBudget 리소스를 통해 스케일 다운 등의 작업이 수행되는 경우에도 유지돼야 하는 최소 파드 개수를 지정하는 방법을 제공한다.

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kubia-pdb
spec:
  minAvailable: 3
  selector:
    matchLabels:
      app: kubia
```

> v1.7 부터는 maxUnavailable 필드를 지원한다. 일정한 개수 이상의 파드가 종료되지 않도록 지정할 수 있다
